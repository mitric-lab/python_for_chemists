# Übung 5

## Aufgabe 1: Lineare Regression

<!--- ANCHOR: aufgabe_1 --->

In der Vorlesung haben Sie eine multilineare Regression an zwei Features
des Wine Quality Datensatzes durchgeführt. In dieser Aufgabe wollen wir
das Thema näher betrachten.

**(a) Analytische Lösung der Multilinearen Regression**

In Kapitel [5.1](../05-machine_learning/01-supervised_learning.md#regression) 
wurde die analytische Lösung der multilinearen Regression in 
Gl. {{eqref: eq:multilinear_regression_solution}} als
$$
\hat{\theta} = (\bm{X}^T \bm{X})^{-1} \bm{X}^T \vec{y}\,,
$$
gegeben. In Kapitel [4.5](../04-evd_and_svd/05-linear_equations.md) wurde in
Gl. {{eqref: eq:multilinear_regression_pinv}} die Lösung aber als
$$
\hat{\theta} = \bm{X}^+ \vec{y}
$$
angegeben. Zeigen Sie, dass die beiden Lösungen äquivalent sind.

*Hinweis: Sie können $(\bm{X}^T \bm{X})^{+} \bm{X}^T = \bm{X}^+$ zeigen, 
indem Sie die Moore-Penrose-Bedingungen 
(Gl. {{eqref: eq:mp_conditions_general_inverse}} - {{eqref: eq:mp_conditions_symmetry_apat}})
für die Matrix $\bm{B} := (\bm{X}^T \bm{X})^{+} \bm{X}^T$ überprüfen. 
Nutzen Sie zudem die Tatsache, dass die Matrix $\bm{X}^T \bm{X}$ invertierbar ist.*

<!--
Lösung:
```python
{{#include ../codes/05-machine_learning/exercise_05_01.py:a}}
```
-->

**(b) Multilineare Regression am Wein Quality Dataset**

In der Vorlesung haben wir nur die Features `alcohol` und `volatile acidity` 
für die multilineare Regression verwendet. Das war zwar gut für die
spätere Visualisierung, aber das Modell beschreibt den Datensatz nur mit
unzureichender Genauigkeit. Mit mehr Features können wir eine bessere
Vorhersage treffen. Führen Sie eine multilineare Regression an allen
Features des Wine Quality Datensatzes durch. Berechnen Sie anschließend die
mittlere quadratische Abweichung (engl. *Mean Squared Error*, MSE) dieser
Regression sowie der Regression an den beiden Features `alcohol` und
`volatile acidity`. Vergleichen Sie die beiden Ergebnisse.

<!--
Lösung:
```python
{{#include ../codes/05-machine_learning/exercise_05_01.py:b}}
```
-->

**(c) Bestimmtheitsmaß**

Während der MSE uns eine quantitative Aussage über die Qualität der
Regression gibt, ist die Interpretation des MSE nur anhand
der Daten bzw. des Kontexts möglich. Ein alternatives Maß ist das
Bestimmtheitsmaß (engl. *coefficient of determination*), auch
als $R^2$ notiert, dessen Wert zwischen 0 und 1 liegt. Damit ist eine
kontextunabhängige Interpretation möglich. Für die multilineare Regression
ist $R^2$ definiert als
$$
  R^2 = \frac{
    \left[ \sum_{i=1}^{N} (y_i - \bar{y}) (\hat{y}_i - \bar{y}) \right]^2
  }{
    \left[ \sum_{i=1}^{N} (y_i - \bar{y})^2 \right]
    \left[ \sum_{i=1}^{N} (\hat{y}_i - \bar{y})^2 \right]
  }\,,
$$
wobei $y_i$ die tatsächlichen Labels, $\hat{y}_i$ die vorhergesagten Labels
und $\bar{y}$ der Mittelwert der Labels sind. 

Berechnen Sie das Bestimmtheitsmaß für die multilineare Regression an
allen Features des Wine Quality Datensatzes sowie für die Regression
an den beiden Features `alcohol` und `volatile acidity`. Vergleichen Sie
die beiden Ergebnisse.

<!--
Lösung:
```python
{{#include ../codes/05-machine_learning/exercise_05_01.py:c}}
```
-->

<!--- ANCHOR_END: aufgabe_1 --->

## Aufgabe 2: Support Vector Machines

<!--- ANCHOR: aufgabe_2 --->
WIP
<!--- ANCHOR_END: aufgabe_2 --->


## Aufgabe 3: Clustering

<!--- ANCHOR: aufgabe_3 --->
WIP
<!--- ANCHOR_END: aufgabe_3 --->

