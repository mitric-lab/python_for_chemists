# Übung 6

## Aufgabe 1: Gradienten der logistischen Regression

<!--- ANCHOR: aufgabe_1 --->
Zeigen Sie, dass die Gradienten der Verlustfunktion der logistischen Regression {{eqref: eq:logistic_loss}} 
nach den Parametern $\vec{w}$ und $b$ gegeben sind durch

$$
\begin{align}
    \frac{\partial \mathcal{L}}{\partial \vec{w}} &= - \sum_{i=1}^N \left[ y_i - \hat{f}(\vec{x}_i) \right] \vec{x}_i \\
    \frac{\partial \mathcal{L}}{\partial b} &= - \sum_{i=1}^N \left[ y_i - \hat{f}(\vec{x}_i) \right] .
\end{align}
$$

Zeigen Sie dazu (unter Benutzung der Kettenregel) zunächst, dass die Ableitung der Sigmoid-Funktion 
$\sigma(z) = \frac{1}{1 + \exp(-z)}$ gegeben ist durch 

$$
    \frac{d \sigma(z)}{dz} = \sigma(z) (1 - \sigma(z)).
$$

Vergleichen Sie die Gradienten der logistischen Regression mit den Gradienten der linearen Regression 
für die Verlustfunktion der Methode der kleinsten Quadrate. Was fällt Ihnen auf?
<!--- ANCHOR_END: aufgabe_1 --->

## Aufgabe 2: Binäre Kreuzentropie

<!--- ANCHOR: aufgabe_2 --->
Wie wir schon in der Vorlesung gesehen haben, ist die Verlustfunktion der Methode der kleinsten 
Quadrate nicht die beste Methode, um Klassifikationsprobleme zu lösen. Für binäre 
Klassifikationsprobleme wird daher in der Regel die binäre Kreuzentropie 

$$
    \mathcal{H} = -\frac{1}{N} \sum_{i=1}^N y_i \log \hat{f}(\vec{x}_i) + (1 - y_i) \log(1 - \hat{f}(\vec{x}_i))
$$

als Verlustfunktion verwendet. Dabei ist $y_i \in \{0, 1\}$ das Label des $i$-ten Datenpunkts, 
und $\hat{f}(\vec{x}_i)$ die Vorhersage des Modells. Hier setzt die Verwendung des Logarithmus 
voraus, dass die Vorhersage des Modells in das Intervall $(0, 1)$ abgebildet wird, also 
Wahrhscheinlichkeiten repräsentiert, was durch die Sigmoid-Funktion erreicht wird.

Modifizieren Sie die Implementierung des SLP anhand des *Circles*-Datensatzes, sodass die 
binäre Kreuzentropie als Verlustfunktion verwendet wird. Beachten Sie, dass Sie dazu die 
Gradienten der Verlustfunktion $\mathcal{H}$ nach den Parametern $\vec{w}$ und $b$ berechnen 
müssen, wobei Ihnen die Ergebnisse der vorherigen Aufgabe helfen können.

Wie ist die Verlustfunktion der negativen log likelihood {{eqref: eq:logistic_loss}} 
der logistischen Regression mit der (binären) Kreuzentropie verwandt?
<!--- ANCHOR_END: aufgabe_2 --->