# Übung 1


## Aufgabe 1: Lineare Regression

<!--- ANCHOR: aufgabe_1 --->

**(a) Analytische Lösung der linearen Regression herleiten.**

In dem obigen Beispiel haben wir die numpy Funktion `np.linalg.solve` verwendet, um die Lösung des Gleichungssystems der linearen Regression "numerisch" zu berechnen. In diesem Zusammenhang bedeutet dies, dass der Computer einer Reihe von Rechenschritten und Algorithmen folgt, um die approximative Lösung des Gleichungssystems zu finden. Für das Gleichungssystem der linearen Regression gibt es jedoch auch eine "analytische" Lösung, die direkt berechnet werden kann.

Zeigen Sie, dass die Lösung des Gleichungssystems {{eqref: eq:least_squares_linear_params}} gegeben ist durch:

$$
    \begin{align}
        \beta_0 &= \bar{y} - \beta_1 \bar{x} \\
        \beta_1 &= \frac{\sum_{i=1}^{N} (x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^{N} (x_i - \bar{x})^2}
    \end{align}
$$

Lösen Sie dazu zunächst die erste Gleichung in {{eqref: eq:least_squares_linear_params}} nach $\beta_0$ auf und setzen Sie das Ergebnis in die zweite Gleichung ein. Verwenden Sie außerdem die Definitionen der Mittelwerte $\bar{x}$ und $\bar{y}$.

**(b) Implementieren der analytischen Lösung für Messdaten von Methylenblau.**

Nutzen Sie die analytische Lösung, um die Parameter der linearen Regression für die Messdaten von Methylenblau explizit zu berechnen. Vergleichen Sie die Ergebnisse mit den Ergebnissen, die Sie mit `np.linalg.solve` erhalten haben.

```admonish info title="Tipp" collapsible=false
Nutzen Sie erneut die Funktion `np.sum`. Zur Berechnung der Mittelwerte $\bar{x}$ und $\bar{y}$ können Sie die numpy Funktion `np.mean` verwenden. Beachten Sie außerdem, dass für numpy Arrays die Operationen `+`, `-`, `*` und `/` elementweise durchgeführt werden.
```

<!-- 
Lösung:
```python
{{#include ../codes/01-regression/exercise_01.py:exercise_01_1}}
```
-->

<!--- ANCHOR_END: aufgabe_1 --->

## Aufgabe 2: Quadratische Regression

<!--- ANCHOR: aufgabe_2 --->

**(a) Matrixgleichung der quadratischen Regression herleiten.**

Die quadratische Regression ist eine Erweiterung der linearen Regression, bei der die abhängige Variable $y$ durch ein Polynom zweiten Grades in der unabhängigen Variable $x$ angenähert wird. Die allgemeine Form der quadratischen Regression ist gegeben durch:

$$
  \hat{f}(\beta; x_i) = \beta_0 + \beta_1 x_i + \beta_2 x_i^2
  {{numeq}}{eq:quad_model}
$$

In Analogie zur linearen Regression können wir die quadratische Regression als ein lineares Modell in den Parametern $\beta = (\beta_0, \beta_1, \beta_2)$ auffassen. Zeigen Sie, dass dieses Modell durch die folgende Matrixgleichung beschrieben wird:

$$
    \begin{pmatrix}
        \displaystyle N & \displaystyle \sum_{i=1}^N\, x_i & \displaystyle \sum_{i=1}^N\, x_i^2 \\[1.5em]
        \displaystyle \sum_{i=1}^N\, x_i & \displaystyle \sum_{i=1}^N\, x_i^2 & \displaystyle \sum_{i=1}^N\, x_i^3 \\[1.5em]
        \displaystyle \sum_{i=1}^N\, x_i ^2 & \displaystyle \sum_{i=1}^N\, x_i^3 & \displaystyle \sum_{i=1}^N\, x_i^4
    \end{pmatrix}
    \begin{pmatrix}
        \displaystyle \beta_0 \\[1.5em]
        \displaystyle \beta_1 \\[1.5em]
        \displaystyle \beta_2
    \end{pmatrix}
    \vphantom{
    \begin{pmatrix}
        \displaystyle \sum_{i=1}^N\, y_i \\[1.5em]
        \displaystyle \sum_{i=1}^N\, x_i y_i \\[1.5em]
        \displaystyle \sum_{i=1}^N\, x_i^2 y_i
    \end{pmatrix}
    }
    =
    \begin{pmatrix}
        \displaystyle \sum_{i=1}^N\, y_i \\[1.5em]
        \displaystyle \sum_{i=1}^N\, x_i y_i \\[1.5em]
        \displaystyle \sum_{i=1}^N\, x_i^2 y_i
    \end{pmatrix}
    {{numeq}}{eq:least_squares_quad_params}
$$

Setzen Sie dazu die quadratische Funktion $\hat{f}(\beta; x_i)$ in die allgemeine Form der Methode der kleinsten Quadrate {{eqref: eq:least_squares_linear_params}} ein und bilden Sie die Ableitungen nach den gesuchten Parametern.

**(b) Quadratische Regression implementieren und an Methylenblau-Daten 
anwenden.**

Fahren Sie nun fort wie für die lineare Regression, indem Sie das Gleichungssystem der quadratischen Regression für die Methylenblau-Daten numerisch lösen. Konstruieren Sie dazu zunächst die benötigten arrays, und verwenden Sie die Funktion `np.linalg.solve`. Plotten Sie anschließend die quadratische Regression zusammen mit den Datenpunkten.

<!-- 
Lösung:
```python
{{#include ../codes/01-regression/exercise_01.py:exercise_01_2}}
```
-->

**(c) `np.polyfit` anwenden und Ergebnis mit der "homebrew" Variante
vergleichen.**




<!--- ANCHOR_END: aufgabe_2 --->

## Aufgabe 3

<!--- ANCHOR: aufgabe_3 --->
Idee: Polynomiale Regression 20. Ordnung mit `minimize`

**(a) Polynomiale Regression 20. Ordnung numerisch implementieren
und an Methylenblau-Daten anwenden.
evtl. mit `polyfit` vergleichen, falls was ähnliches rauskommt.**

**(b) Polynomiale Regression 20. Ordnung mit l1-Norm numerisch implementieren
und an Methylenblau-Daten anwenden.**

**(c) Polynomiale Regression 20. Ordnung mit Ridge- bzw. Lasso-Regression
implementieren und an Methylenblau-Daten anwenden.**

**(d) Erkläre anschaulich, wie Regularisierung wirkt. 
Hinweis: Linreg mit einem Punkt.**
<!--- ANCHOR_END: aufgabe_3 --->

## Aufgabe 3

<!--- ANCHOR: aufgabe_3 --->
Keine Ahnung... Irgendein anderes nichtlineares Modell?
Oder Mn-Zerfall bzw. Titration mit Regularisierung?
<!--- ANCHOR_END: aufgabe_3 --->

