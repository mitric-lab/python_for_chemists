<!DOCTYPE HTML>
<html lang="de" class="latte" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Numerische Optimierung - Programmierkurs für Chemiker</title>


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../highlight.css">
        <link rel="stylesheet" href="../tomorrow-night.css">
        <link rel="stylesheet" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href=".././theme/catppuccin.css">
        <link rel="stylesheet" href=".././theme/catppuccin-admonish.css">
        <link rel="stylesheet" href=".././theme/mdbook-admonish.css">
        <link rel="stylesheet" href=".././theme/mdbook-admonish-custom.css">
        <link rel="stylesheet" href=".././theme/icomoon.css">
        <link rel="stylesheet" href=".././theme/pagetoc.css">
        <link rel="stylesheet" href=".././mdbook-admonish.css">

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "mocha" : "latte";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('latte')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><li class="part-title">Inhaltsverzeichnis</li><li class="chapter-item expanded "><a href="../00-preface.html"><strong aria-hidden="true">0.</strong> Vorwort</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../00-preface/01-motivation.html"><strong aria-hidden="true">0.1.</strong> Motivation</a></li><li class="chapter-item "><a href="../00-preface/02-getting_started.html"><strong aria-hidden="true">0.2.</strong> Erste Schritte</a></li><li class="chapter-item "><a href="../00-preface/03-mdbook_usage.html"><strong aria-hidden="true">0.3.</strong> Bedienung dieser Website</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../01-regression.html"><strong aria-hidden="true">1.</strong> Regressionsanalyse</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../01-regression/01-least_squares.html"><strong aria-hidden="true">1.1.</strong> Methode der kleinsten Quadrate</a></li><li class="chapter-item "><a href="../01-regression/02-linear_regression.html"><strong aria-hidden="true">1.2.</strong> Lineare Regression</a></li><li class="chapter-item expanded "><a href="../01-regression/03-numerical_optimisation.html" class="active"><strong aria-hidden="true">1.3.</strong> Numerische Optimierung</a></li><li class="chapter-item "><a href="../01-regression/04-nonlinear_regression.html"><strong aria-hidden="true">1.4.</strong> Nichtlineare Regression</a></li></ol></li><li class="chapter-item expanded "><a href="../02-differential_equations.html"><strong aria-hidden="true">2.</strong> Differentialgleichungen</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../02-differential_equations/01-initial_value_problem.html"><strong aria-hidden="true">2.1.</strong> Anfangswertproblem</a></li><li class="chapter-item "><a href="../02-differential_equations/02-euler_method.html"><strong aria-hidden="true">2.2.</strong> Euler-Verfahren</a></li><li class="chapter-item "><a href="../02-differential_equations/03-runge_kutta.html"><strong aria-hidden="true">2.3.</strong> Runge-Kutta-Verfahren</a></li><li class="chapter-item "><a href="../02-differential_equations/04-finite_differences.html"><strong aria-hidden="true">2.4.</strong> Finite-Differenzen-Verfahren</a></li></ol></li><li class="chapter-item expanded "><a href="../03-fourier_analysis.html"><strong aria-hidden="true">3.</strong> Fourier-Analyse</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../03-fourier_analysis/01-fourier_series.html"><strong aria-hidden="true">3.1.</strong> Fourier-Reihen</a></li><li class="chapter-item "><a href="../03-fourier_analysis/02-fourier_transform.html"><strong aria-hidden="true">3.2.</strong> Fourier-Transformation</a></li><li class="chapter-item "><a href="../03-fourier_analysis/03-discrete_fourier_transform.html"><strong aria-hidden="true">3.3.</strong> Diskrete Fourier-Transformation</a></li></ol></li><li class="chapter-item expanded "><a href="../04-evd_and_svd.html"><strong aria-hidden="true">4.</strong> Eigenwert- und Singulärwertzerlegung</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../04-evd_and_svd/01-eigenvalue_decomposition.html"><strong aria-hidden="true">4.1.</strong> Eigenwertzerlegung</a></li><li class="chapter-item "><a href="../04-evd_and_svd/02-singular_value_decomposition.html"><strong aria-hidden="true">4.2.</strong> Singulärwertzerlegung</a></li><li class="chapter-item "><a href="../04-evd_and_svd/03-principal_component_analysis.html"><strong aria-hidden="true">4.3.</strong> Hauptkomponentenanalyse</a></li><li class="chapter-item "><a href="../04-evd_and_svd/04-principal_coordinate_analysis.html"><strong aria-hidden="true">4.4.</strong> Hauptkoordinatenanalyse</a></li><li class="chapter-item "><a href="../04-evd_and_svd/05-linear_equations.html"><strong aria-hidden="true">4.5.</strong> Lineare Gleichungssysteme</a></li></ol></li><li class="chapter-item expanded "><a href="../05-machine_learning.html"><strong aria-hidden="true">5.</strong> Maschinelles Lernen</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../05-machine_learning/01-supervised_learning.html"><strong aria-hidden="true">5.1.</strong> Überwachtes Lernen</a></li><li class="chapter-item "><a href="../05-machine_learning/02-unsupervised_learning.html"><strong aria-hidden="true">5.2.</strong> Unüberwachtes Lernen</a></li></ol></li><li class="chapter-item expanded "><a href="../06-neural_networks.html"><strong aria-hidden="true">6.</strong> Neuronale Netzwerke</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="../06-neural_networks/01-single_layer_perceptron.html"><strong aria-hidden="true">6.1.</strong> Single-Layer-Perzeptron</a></li><li class="chapter-item "><a href="../06-neural_networks/02-multi_layer_perceptron.html"><strong aria-hidden="true">6.2.</strong> Multi-Layer-Perzeptron</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="../07-summary.html">Zusammenfassung und Ausblick</a></li><li class="spacer"></li><li class="chapter-item expanded affix "><a href="../psets/01.html">Übung 1</a></li><li class="chapter-item expanded affix "><a href="../psets/02.html">Übung 2</a></li><li class="chapter-item expanded affix "><a href="../psets/03.html">Übung 3</a></li><li class="chapter-item expanded affix "><a href="../psets/04.html">Übung 4</a></li><li class="chapter-item expanded affix "><a href="../psets/05.html">Übung 5</a></li><li class="chapter-item expanded affix "><a href="../psets/06.html">Übung 6</a></li><li class="chapter-item expanded affix "><a href="../psets/exam_preparation.html">Klausurvorbereitung</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="latte">Latte</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="frappe">Frappé</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="macchiato">Macchiato</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mocha">Mocha</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Programmierkurs für Chemiker</h1>

                    <div class="right-buttons">
			<!--print button-->
			<a href="../print.html" title="Buch drucken" aria-label="Buch drucken">
			    <i id="print-button" class="fa fa-print"></i>
			</a>

                        
                        <!-- WueCampus button -->
                        <script>
                            var wueCampusLink = "https://wuecampus.uni-wuerzburg.de/moodle/course/view.php?id=66271";
                        </script>
			<a href="javascript:void(0);" onclick="window.open(wueCampusLink)" target="_blank" rel="noopener noreferrer" title="WueCampus-Kursraum besuchen" aria-label="WueCampus-Kursraum besuchen">
			    <i id="wuecampus-button" class="icon-uw"></i>
			</a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main><div class="sidetoc"><nav class="pagetoc"></nav></div>
                        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h2 id="numerische-optimierung"><a class="header" href="#numerische-optimierung">Numerische Optimierung</a></h2>
<p>Die numerische Optimierung bietet uns die Möglichkeit, komplexe Funktionen,
wie die Verlustfunktionen der kleinsten Quadrate
(Gl. <a href="01-least_squares.html#eq:least_squares_loss">(1.3)</a>), aber auch Funktionen im anderen
Kontext, wie z.B. die Energie eines Moleküls, zu minimieren oder maximieren.
Da die Maximierung einer Funktion <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span> äquivalent zur Minimierung von <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord">−</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span>
ist, werden wir im Folgenden nur noch vom Minimieren sprechen.
Die Fähigkeit, Optimierungsprobleme anzugehen,
für die keine geschlossenen Lösungsformeln existieren, oder die Auswertung
des analytischen Ausdrucks zu aufwendig ist,
erweitert unser Werkzeugset in der Datenanalyse signifikant. Insbesondere
erlaubt sie es, Lösungen für Modelle zu finden, die durch
Nichtlinearitäten, hohe Dimensionalitäten oder ungewöhnliche
Datenverteilungen charakterisiert sind.</p>
<h3 id="theoretische-grundlagen"><a class="header" href="#theoretische-grundlagen">Theoretische Grundlagen</a></h3>
<p>Ein besonders zugänglicher und grundlegender Ansatz für die numerische
Optimierung ist das
<a href="https://de.wikipedia.org/wiki/Gradientenverfahren">Gradientenverfahren</a>
(engl. <em>Gradient Descent</em>). Dies ist ein <em>iteratives Verfahren</em>, welches
von einem gegebenen Startpunkt <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span></span></span></span> ausgeht und in jedem Schritt der
Richtung des steilsten Abstiegs der Funktion folgt. Mathematisch
formuliert heißt das
<span class="katex-display"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8991em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.9824em;vertical-align:-0.0833em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1491em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mord">∇</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="enclosing" id="eq:gradient_descent"></span></span><span class="tag"><span class="strut" style="height:1.1491em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">1.10</span></span><span class="mord">)</span></span></span></span></span></span>
wobei <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8491em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span></span></span></span></span></span></span> der Schätzwert des Minimums im <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span>-ten Schritt ist. Das
hochgestellte <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> hat hier nichts mit Potenzierung zu tun, sondern ist
lediglich eine Notation,
um die Verwechselung mit der <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span>-ten Komponente des Vektors, die hier tiefgestellt wird,
zu vermeiden. Der Gradient der <em>Objektivfunktion</em> <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span> bei <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8491em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span></span></span></span></span></span></span> kann dann als
<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0991em;vertical-align:-0.25em;"></span><span class="mord">∇</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.8543em;vertical-align:-0.65em;"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9322em;"><span style="top:-2.6014em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8408em;"><span style="top:-2.1885em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span><span style="top:-2.8448em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3115em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.4461em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.6166em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9322em;"><span style="top:-2.6426em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.782em;"><span style="top:-2.214em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">n</span></span></span><span style="top:-2.786em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.4461em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5576em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">)</span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.2043em;"><span style="top:-3.6029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord amsrm mtight">⊺</span></span></span></span></span></span></span></span></span></span></span></span>
notiert werden.
Die Propotionialitätskonstante <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span> wird als <em>Schrittweite</em> oder
<em>learning rate</em> bezeichnet. Das Verfahren wird solange wiederholt, bis
eine oder mehrere Abbruchbedingungen erfüllt sind. Typische
Abbruchbedingungen für iterative Optimierungsverfahren sind:</p>
<ul>
<li>Die Änderung des Funktionswertes ist kleiner als ein Schwellenwert</li>
<li>Die Änderung des Schätzwertes ist kleiner als ein Schwellenwert</li>
<li>Eine maximale Anzahl an Iterationen ist erreicht</li>
<li>Die Norm des Gradienten ist kleiner als ein Schwellenwert.</li>
</ul>
<p>Die Schrittweite <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span> ist der einzige und zugleich ein wichtiger
Parameter des Gradientenverfahrens, da sie die Konvergenzgeschwindigkeit
und die Stabilität des Verfahrens beeinflusst.
Ein zu kleiner Wert für <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span> kann dazu
führen, dass das Verfahren sehr langsam konvergiert, während ein zu
großer Wert dazu führen kann, dass das Verfahren divergiert.</p>
<p>Damit wir das Gradientenverfahren nutzen können, müssen wir Zugang zum
Gradienten der Objektivfunktion haben. Liegt dieser nicht analytisch vor,
muss eine numerische Approximation verwendet werden. Ein einfacher Ansatz
liefert die Methode der
<a href="https://en.wikipedia.org/wiki/Finite_difference">Finite Differenz</a>
. Hierbei wird die tangente der partiellen Ableitung durch die
Sekante ersetzt, was zu einer Approximation der Form
<span class="katex-display"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.3692em;vertical-align:-0.9978em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.2791em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8309em;"><span style="top:-2.4231em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.0448em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2769em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9978em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.2121em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5261em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span><span class="mord mathnormal">h</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal">h</span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">e</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal">h</span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">e</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="enclosing" id="eq:finite_difference_symmetric"></span></span><span class="tag"><span class="strut" style="height:2.5239em;vertical-align:-0.9978em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">1.11</span></span><span class="mord">)</span></span></span></span></span></span>
führt. Zudem ist <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">e</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> der <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span>-te Einheitsvektor und <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">h</span></span></span></span> ein
kleiner Wert, der die Schrittweite der Approximation bestimmt. Genau
genommen stellt Gl. <a href="#eq:finite_difference_symmetric">(1.11)</a> die
<em>zentrale finite Differenz 2. Ordnung</em> dar. Es gibt auch <em>einseitige</em>
Approximationen und Approximationen höherer Ordnung, die wir hier aber
nicht weiter betrachten.</p>
<h3 id="implementierung"><a class="header" href="#implementierung">Implementierung</a></h3>
<h4 id="finite-differenz"><a class="header" href="#finite-differenz">Finite Differenz</a></h4>
<p>Als erstes implementieren wir die finite Differenz. Da wir mehrmals
Ableitungen berechnen werden müssen, ist es sinnvoll, eine <em>Funktion</em> zu
implementieren. Funktionen im Programmierkontext sind ähnlich zu
mathematischen Funktionen, die eine Eingabe in eine Ausgabe umwandeln. Sie
können aber noch einiges mehr.</p>
<p>Wir importieren zuerst <code>numpy</code> und die Objekte <code>Callable</code> und <code>Any</code>
aus dem Modul <code>typing</code>:</p>
<pre><code class="language-python">import numpy as np
from typing import Callable, Any
</code></pre>
<p>Dann definieren wir die Funktion <code>finite_difference</code>, die den Gradienten einer
Funktion <code>func</code> an der Stelle <code>x0</code> berechnet.</p>
<pre><code class="language-python">def finite_difference(
    func: Callable[[np.ndarray, Any], float],
    x0: np.ndarray,
    h: float = 1e-5,
    args: tuple = (),
) -&gt; np.ndarray:
    n: int = len(x0)
    grad: np.ndarray = np.zeros(n)

    for i in range(0, n):
        e: np.ndarray = np.zeros(n)
        e[i] = 1
        grad[i] = (
            func(x0 + h * e, *args) - func(x0 - h * e, *args)
        ) / (2 * h)

    return grad
</code></pre>
<p>Der erste Block der Funktion ist die <em>Signatur</em>, die angibt, welche
Argumente die Funktion erwartet und welchen Typ die Rückgabe hat. Hierfür
wurden die Objekte <code>Callable</code> und <code>Any</code> benutzt. Obwohl die explizite Angabe
der Datentypen in Python optional und immer noch selten ist, ist es nach
Meinung der Autoren eine gute Praxis. Näheres dazu finden Sie in dem
folgenden</p>
<details id="admonition-infokasten" class="admonition admonish-info">
<summary class="admonition-title">
<p>Infokasten</p>
<p><a class="admonition-anchor-link" href="#admonition-infokasten"></a></p>
</summary>
<div>
<p>Eine Analogie zur Signatur in der Mathematik ist die Definitionsmenge und
der Wertebereich einer Funktion, die einschränken, welche Argumente
akzeptiert werden und welche Werte zurückgegeben werden. So funktioniert
auch die Signatur in Computerprogrammen.</p>
<p>In statisch typisierten (engl. <em>statically typed</em>) Programmiersprachen,
wie C++, Java oder Rust, müssen Funktionen explizite Signaturen haben.
Diese Angabe wird vom Compiler verwendet, um sicherzustellen, dass die
Funktion korrekt verwendet wird und ggf. Optimierungen durchzuführen.</p>
<p>Als Beispiel dient hier eine naive Implementierung der Funktion <code>powi</code>
in Rust, die die ganzzahlige Potenz einer Gleitkommazahl berechnet:</p>
<pre><pre class="playground"><code class="language-rust no_run no_playground"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn powi(x: f64, n: i32) -&gt; f64 {
    let mut result: f64 = 1.0;
    for _ in 0..n {
        result *= x;
    }
    result
}
<span class="boring">}</span></code></pre></pre>
<p>Während die Details dieser Funktion uns nicht interessieren, ist die
erste Zeile des Codeblocks <code>fn powi(x: f64, n: i32) -&gt; f64</code> wichtig,
da sie die Signatur der Funktion enthält. Man erkennt, dass die Funktion
<code>powi</code> zwei Argumente vom Typ <code>f64</code> und <code>i32</code> erwartet und einen Wert vom
Typ <code>f64</code> zurückgibt.</p>
<p>Eine übliche Implementierung dieser Funktion in Python könnte so aussehen:</p>
<pre><code class="language-python">def powi(x, n):
    result = 1.0
    for _ in range(n):
        result *= x
    return result
</code></pre>
<p>Hier gibt es keine explizite Signatur, da Python eine dynamisch typisierte
(engl. <em>dynamically typed</em>) Programmiersprache ist. An dieser Funktion erkennt
man auf dem ersten Blick nicht, ob sie für Ganz- oder Gleitkommazahlen
gedacht ist. Um diese Funktion also korrekt zu verwenden, muss man sich mit
der genauen Implementierung auseinandersetzen, während man durch die Signatur
sofort weiß, welche Argumente erwartet werden.</p>
<p>Deshalb empfehlen die Autoren, obwohl der Python-Interpreter keine
explizite Typisierung erfordert, die Verwendung von Typen in der Signatur
von Funktionen, um die Lesbarkeit und Wartbarkeit des Codes zu verbessern.</p>
</div>
</details>
<p>Die Signatur der Funktion <code>finite_difference</code> besagt, dass sie eine
Funktion <code>func</code> erwartet, die als Argument einen np.ndarray und
irgendwas (<code>Any</code>) akzeptiert und einen Float zurückgibt.
Die weiteren Argumente sind der Punkt <code>x0</code> vom Typ np.ndarray, an dem
der Gradient berechnet werden soll, die Schrittweite <code>h</code> vom Typ Float
und ein <em>Tuple</em> (engl. <em>tuple</em>) <code>args</code>, das zusätzliche Argumente für die
Funktion <code>func</code> liefern kann. Außerdem haben wir in der Signatur
voreingestellte (engl. <em>default</em>) Werte für <code>h</code> und <code>args</code> definiert.
Das bedeutet, dass die Werte <code>h = 1e-5</code> und <code>args = ()</code>
verwendet werden, wenn die Funktion <code>finite_difference</code> ohne die
Argumente <code>h</code> und <code>args</code> aufgerufen wird.</p>
<p>In der Funktion wird zuerst die Dimension des Punktes <code>x0</code> bestimmt und
in der Integer <code>n</code> gespeichert. Der Gradient einer reellwertigen
Funktion mit <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span> Variablen ist ein Vektor der Länge <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span>. Daher wird
die Variable <code>grad</code> als ein np.ndarray der Länge <code>n</code> aus Nullen
durch die Funktion
<a href="https://numpy.org/doc/stable/reference/generated/numpy.zeros.html"><code>np.zeros</code></a>
initialisiert.</p>
<p>Weil wir Gl. <a href="#eq:finite_difference_symmetric">(1.11)</a> auf alle <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span>
Komponenten des Punktes <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8491em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span></span></span></span></span></span></span> anwenden müssen, ist die Nutzung einer
<em>Schleife</em> (engl. <em>loop</em>) sinnvoll. Hier benutzen wir eine
<a href="https://docs.python.org/3/tutorial/controlflow.html#for-statements"><em>for</em>-Schleife</a>,
die über alle Indizes <code>i</code> von <code>0</code> bis <code>n - 1</code> iteriert. Beachten Sie, dass
Python-Indizes bei <code>0</code> beginnen und die built-in Funktion
<a href="https://docs.python.org/3/library/functions.html#func-range"><code>range</code></a>
den Endwert <code>n</code> nicht einschließt.</p>
<p>In jeder Iteration der Schleife definieren wir zuerst den Einheitsvektor
<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">e</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, indem wir zuerst ein Null-Array der Länge <code>n</code> mit
<code>np.zeros(n)</code> erstellen und dann die <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span>-te Komponente auf <code>1</code> setzen.
Danach können wir den <code>i</code>-ten Eintrag des Gradientenarrays <code>grad</code> gemäß
Gl. <a href="#eq:finite_difference_symmetric">(1.11)</a> berechnen. Der einzige
Unterschied zwischen unserem Code und dieser Gleichung ist, dass wir das
Zusatzargument <code>args</code> an die Funktion <code>func</code> übergeben, wobei
ein Stern <code>*</code> vor dem Argument <code>args</code> steht. Die Verwendung
von <code>*</code> wirkt an dieser Stelle als einen unären Operator,
der ein Objekt in seine Bestandteile entpackt
(engl. <a href="https://docs.python.org/3/tutorial/controlflow.html#unpacking-argument-lists"><em>unpacking</em></a>).
Das bedeutet, dass die Funktion <code>func</code> nach dem ersten Argument
die weitere Argumente im Tuple <code>args</code> <strong>einzelnd</strong> akzeptiert.</p>
<p>Nach der letzten Iteration geben wir den Gradienten in Form der Variable <code>grad</code>
zurück.</p>
<h4 id="objektivfunktion"><a class="header" href="#objektivfunktion">Objektivfunktion</a></h4>
<p>Als nächstes implementieren wir die Objektivfunktion, deren Wert wir
minimieren wollen. Gemäß Gl. <a href="02-linear_regression.html#eq:least_squares_loss_linear">(1.8)</a>
können wir die Funktion <code>objective_function</code> folgendermaßen definieren:</p>
<pre><code class="language-python">def objective_function(
    beta: np.ndarray,
    *args: np.ndarray,
) -&gt; float:
    concentrations: np.ndarray = args[0]
    absorbances: np.ndarray = args[1]
    return np.sum((absorbances - (beta[0] + beta[1] * concentrations))**2)
</code></pre>
<p>Die Signatur der Funktion <code>objective_function</code> folgt der Typdefinition
des Arguments <code>func</code> in der Funktion <code>finite_difference</code>
(<code>Callable[[np.ndarray, Any], float]</code>):</p>
<ul>
<li>Das Argument <code>beta</code> ist vom Typ np.ndarray,</li>
<li>das Argument <code>args</code> ist vom Typ np.ndarray, also auch <code>Any</code> und</li>
<li>die Funktion gibt einen Float zurück.</li>
</ul>
<p>Hier sehen wir wieder die Verwendung von <code>*</code> vor dem Argument <code>args</code>.
In diesem Fall heißt das, dass die Funktion <code>objective_function</code> beliebig
viele weitere Argumente nach <code>beta</code> akzeptiert.</p>
<p>Die Funktion <code>objective_function</code> definiert zuerst die Arrays
<code>concenctrations</code> und <code>absorbances</code> aus dem Argument <code>args</code>
und gibt anschließend den Wert der Verlustfunktion der kleinsten
Quadrate gemäß Gl. <a href="02-linear_regression.html#eq:least_squares_loss_linear">(1.8)</a> zurück.
Hier gibt es erneut keine große Unterschiede zwischen der mathematischen
Formulierung und der programmatischen Implementierung.</p>
<p>Mit Hilfe der Funktionen <code>finite_difference</code> können wir die Funktion
<code>objective_function_gradient</code> implementieren, die den Gradienten der
Objektivfunktion berechnet:</p>
<pre><code class="language-python">def objective_function_gradient(
    beta: np.ndarray,
    *args: np.ndarray,
) -&gt; np.ndarray:
    concentrations: np.ndarray = args[0]
    absorbances: np.ndarray = args[1]
    grad: np.ndarray = finite_difference(
        objective_function, 
        beta, 
        args=(concentrations, absorbances),
    )
    return grad
</code></pre>
<p>Die Signatur dieser Funktion ist ähnlich zu der der Funktion
<code>objective_function</code>; lediglich der Rückgabetyp ist ein np.ndarray.
Erinnern Sie sich daran, dass, da die Objektivfunktion einen
<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span>-dimensionalen Vektor als Argument hat, der Gradient
ebenfalls ein <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span>-dimensionaler Vektor ist.
Nach der Definition der Arrays <code>concenctrations</code> und <code>absorbances</code>
berechnen wir den Gradienten der Objektivfunktion einfach durch
Aufrufen der Funktion <code>finite_difference</code>. Der Rückgabewert wird in der
Variable <code>grad</code> gespeichert und zurückgegeben.</p>
<h4 id="gradientenverfahren"><a class="header" href="#gradientenverfahren">Gradientenverfahren</a></h4>
<p>Anschließend implementieren wir das Gradientenverfahren.
Aus Gl. <a href="#eq:gradient_descent">(1.10)</a> folgt, dass wir zum Starten des Verfahrens
den Gradienten der Objektivfunktion <code>func_grad</code>, den Startpunkt <code>x0</code>
und die Schrittweite <code>alpha</code> benötigen. Als Abbruchbedingung verwenden
wir eine Kombination aus der maximalen Anzahl an Iterationen und der Norm
des Gradienten. Das führt zu den zusätzlichen Argumenten <code>max_iter</code> und
<code>max_norm</code>. Außerdem brauchen wir noch das Argument <code>args</code>, das die
weiteren Argumente für die Funktion <code>func_grad</code> enthält.</p>
<pre><code class="language-python">def gradient_descent(
    func_grad: Callable[[np.ndarray, Any], np.ndarray],
    x0: np.ndarray,
    alpha: float = 0.001,
    max_norm: float = 1e-6,
    max_iter: int = 10000,
    args: tuple = (),
) -&gt; tuple[np.ndarray, int]:
    x: np.ndarray = np.copy(x0)
    for niter in range(0, max_iter):
        grad: np.ndarray = func_grad(x, *args)
        x = x - alpha * grad
        if np.linalg.norm(grad) &lt; max_norm:
            break
    if niter == max_iter - 1:
        print('Warning: Maximum iterations reached. '
              'Result may not be reliable.')
    
    return x, niter
</code></pre>
<p>Zuerst kopieren wir explizit den Array <code>x0</code> mit der Funktion
<code>np.copy</code> und speichern die Kopie in der Variable <code>x</code>. Das ist notwendig,
da Python standardmäßig Arrays nicht kopiert, sondern nur Referenzen
auf sie speichert. Das bedeutet, dass, wenn wir <code>x0</code> ändern, auch <code>x</code>
geändert wird. Um das zu vermeiden, kopieren wir den Array explizit.</p>
<p>Danach verwenden
wir eine <code>for</code>-Schleife, die die Variable <code>niter</code> von <code>0</code> bis <code>max_iter - 1</code>
iteriert. In jeder Iteration berechnen wir den Gradienten <code>grad</code> durch
Aufrufen der Funktion <code>func_grad</code> mit den Argumenten <code>x</code> und <code>args</code>.
Anschließend verwenden wir Gl. <a href="#eq:gradient_descent">(1.10)</a> um die Variable
<code>x</code> zu aktualisieren. Danach berechnen wir die Norm des Gradienten
mit der Funktion
<a href="https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html"><code>np.linalg.norm</code></a>
und prüfen, ob sie kleiner als <code>max_norm</code> ist. Wenn ja, brechen wir die
Schleife mit dem <code>break</code>-Befehl ab.</p>
<p>Nach der letzen Iteration überprüfen wir, ob die Variable <code>niter</code> die maximale
Anzahl an Iterationen erreicht hat. Wenn ja, bedeutet das, dass das verfahren
möglicherweise nicht konvergiert ist und wir geben wir eine Warnung aus.
Am Ende geben wir das Optimum <code>x</code> so wie die Anzahl der tatsächlich benötigten I
terationen <code>niter</code> zurück.</p>
<h3 id="anwendung"><a class="header" href="#anwendung">Anwendung</a></h3>
<p>Nun können wir den implementierten Algorithmus auf die Daten aus Kapitel
<a href="02-linear_regression.html">1.2</a> anwenden. Dazu definieren wir als erstes
wieder die Arrays <code>concentrations</code> und <code>absorbances</code>:</p>
<pre><code class="language-python">concentrations = [
    2.125, 4.250, 6.375, 8.500, 10.63, 12.75, 14.88, 17.00, 19.13, 21.25,
    23.38, 25.50, 27.63, 29.75, 31.88, 34.00, 36.13, 38.25, 40.38, 42.50,
]
absorbances = [
    0.0572, 0.1391, 0.2049, 0.2754, 0.3420, 
    0.4139, 0.4956, 0.5815, 0.6806, 0.7481,
    0.8242, 0.9130, 1.0043, 1.0809, 1.1511,
    1.2483, 1.3373, 1.4027, 1.4927, 1.5853,
]
concentrations: np.ndarray = np.array(concentrations)
absorbances: np.ndarray = np.array(absorbances)
</code></pre>
<p>Dann definieren wir den Startpunkt <code>x0</code>, hier <code>beta_guess</code>, und rufen die Funktion
<code>gradient_descent</code> auf:</p>
<pre><code class="language-python">beta_guess = np.array([1.0, 1.0])
beta_opt, niter = gradient_descent(
    objective_function_gradient, 
    beta_guess,
    alpha=0.00005,
    max_iter=100000,
    args=(concentrations, absorbances),
)

beta0, beta1 = beta_opt
assert np.isclose(beta0, -0.04907034)
assert np.isclose(beta1, 0.03800109)

print(beta_opt)
print(niter)
</code></pre>
<p>Die optimalen Parameter <code>beta0</code> und <code>beta1</code> sind identisch wie die der analytischen
Lösung. Auf dem Computer des Autors wurden 34683 Iterationen benötigt, um
die Abbruchbedingung zu erfüllen. Die genaue Anzahl der Iterationen kann
je nach Hardware leicht variieren. Wählt man die Schrittweite <code>alpha</code>
geringfügig größer, werden weniger Iterationen benötigt. Ist <code>alpha</code>
aber zu groß, divergiert das Verfahren.</p>
<div id="admonition-tipp" class="admonition admonish-tip">
<div class="admonition-title">
<p>Tipp</p>
<p><a class="admonition-anchor-link" href="#admonition-tipp"></a></p>
</div>
<div>
<p>Versuchen Sie, die Schrittweite <code>alpha</code> zu verändern und beobachten Sie, wie
sich die Anzahl der Iterationen ändert.</p>
</div>
</div>
<p>Da Optimierung ein sehr allgemeines Problem ist, existieren viele
Implementierungen von verschiedensten Algorithmen in Bibliotheken wie z.B.
<a href="https://docs.scipy.org/doc/scipy/reference/optimize.html"><code>scipy.optimize</code></a>.
Wir wollen die Funktion
<a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html"><code>scipy.optimize.minimize</code></a>
verwenden, um die optimalen Parameter <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span> zu finden:</p>
<pre><code class="language-python">from scipy.optimize import minimize

res = minimize(
    objective_function,
    beta_guess,
    args=(concentrations, absorbances),
    method='CG',
    jac=objective_function_gradient,
    options={'maxiter': 10000, 'gtol': 1e-6},
)

beta0, beta1 = res.x
niter = res.nit
assert np.isclose(beta0, -0.04907034)
assert np.isclose(beta1, 0.03800109)
</code></pre>
<p>Beim Aufrufen der Funktion <code>minimize</code> müssen wir nur die Objektivfunktion
<code>objective_function</code> und den Startpunkt <code>beta_guess</code> angeben. Um die
Berechnung der numerischen Gradienten kümmert sich die <code>minimize</code>-Funktion
selbst.</p>
<div id="admonition-anmerkung-zur-funktion-minimize" class="admonition admonish-note">
<div class="admonition-title">
<p>Anmerkung zur Funktion <code>minimize</code></p>
<p><a class="admonition-anchor-link" href="#admonition-anmerkung-zur-funktion-minimize"></a></p>
</div>
<div>
<p>Die Funktion <code>minimize</code> akzeptiert auch das Argument <code>jac</code>
(<a href="https://de.wikipedia.org/wiki/Jacobi-Matrix">Jacobi-Matrix</a>), also eine Funktion,
die den Gradienten der Objektivfunktion berechnet. Sollte man den analytischen
und leicht zu berechnenden Gradienten zur Verfügung haben, kann man ihn als
Argument <code>jac</code> übergeben, was den Optimierungsprozess beschleunigen kann.</p>
</div>
</div>
<p>Mit dem Argument <code>method='CG'</code> haben wir die
<em>Methode des nichtlinearen Konjugierten Gradienten</em>
(engl. <a href="https://en.wikipedia.org/wiki/Nonlinear_conjugate_gradient_method"><i>nonlinear <strong>C</strong>onjugate <strong>G</strong>radient method</i></a>)
ausgewählt. Diese Methode ist ein Verbesseung des Gradientenverfahrens und
erreicht das Minimum in nur 2 Iterationen auf dem Computer des Autors.</p>
<p>Bei <code>minimize</code> gibt es eine Reihe von weiteren Minimierungsmethoden, die
verwendet werden können. Eine Übersicht finden Sie in der
<a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html">Dokumentation</a> dieser Funktion. Zwei wichtige Methoden davon sind:</p>
<ul>
<li><code>method='Nelder-Mead'</code>:
Das <a href="https://de.wikipedia.org/wiki/Downhill-Simplex-Verfahren">Nelder-Mead-Verfahren</a>
ist eine heutristische Methode, die ohne die Berechnung des Gradienten
auskommt. Sie ist daher besonders nützlich, wenn die Berechnung des
Gradienten sehr aufwendig ist oder dieser stark variiert. Sie eignet sich deshalb
besonders für Regressionen mit experimentellen Daten.</li>
<li><code>method='BFGS'</code>:
Das <a href="https://de.wikipedia.org/wiki/BFGS-Verfahren">Broyden-Fletcher-Goldfarb-Shanno-Verfahren</a>
ist eine Methode, die den Gradienten benutzt, um die Hesse-Matrix der
Objektivfunktion zu approximieren. Die Hesse-Matrix enthält die zweiten
Ableitungen der Funktion nach ihren Parametern. Die Methode zeigt deshaln eine
sehr schnelle Konvergenz in der Nähe des Minimums. In der Praxis benögtigt sie weniger
Iterationen als andere Optimierungsmethoden und wird deshalb häufig verwendet.</li>
</ul>
<p>Wir werden in der Übung sehen, dass es für die Regression mit der Methode der kleinsten Quadrate
eine geschlossene Lösung gibt, die die optimalen Parameter direkt berechnet.
Warum sollten wir dann die numerische Optimierung verwenden?
Im Kontext der Regression erlaubt uns die numerische Optimierung
einerseits den Einsatz komplizierterer Modelle, die keine analytische
Lösung haben, und andererseits die Verwendung sophistizierterer
Verlustfunktionen, wie z.B. die der Methode der kleinsten absoluten
Abweichungen (vgl. Gl. <a href="01-least_squares.html#eq:least_absolute_deviations_opt">(1.6)</a>).
Zudem können wir damit eine zusätzliche Kontrolle über die Parameter
einführen (<strong>Regularisierung</strong>), was die allgemeine Leistung des Modells
verbessern kann.</p>
<div id="admonition-funktion-scipyoptimizecurve_fit" class="admonition admonish-note">
<div class="admonition-title">
<p>Funktion <code>scipy.optimize.curve_fit</code></p>
<p><a class="admonition-anchor-link" href="#admonition-funktion-scipyoptimizecurve_fit"></a></p>
</div>
<div>
<p>Es gibt auch die Funktion
<a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html"><code>scipy.optimize.curve_fit</code></a>,
die eine (nichtlineare) Regression der Daten direkt durchführt.
Allerdings ist sie nicht so flexibel wie die allgemeine Methode mit der Funktion
<code>minimize</code>, da sie nur über wenige Optimierungsmethoden verfügt und die
Objektivfunktion als die Verlustfunktion der kleinsten Quadrate festlegt.
Sie kann für einfache Regressionen angewendet werden und benötigt in der Regel
weniger Code.</p>
</div>
</div>
<hr />
<h3 id="Übung"><a class="header" href="#Übung">Übung</a></h3>
<h4 id="aufgabe-12-polynomiale-regression"><a class="header" href="#aufgabe-12-polynomiale-regression">Aufgabe 1.2: Polynomiale Regression</a></h4>
<p>Basierend auf der vorherigen Aufgabe, in welcher Sie von der linearen
Regression zur quadratischen Regression übergegangen sind, können Sie
bereits vermuten, dass die Methode der kleinsten Quadrate auch mit
höhergradige Polynomen simpel zu implementieren ist. In der Praxis ist es jedoch
nicht sinnvoll, die Gleichungssysteme für Polynome höheren Grades
manuell zu lösen. Stattdessen können Sie die Funktion
<a href="https://numpy.org/doc/stable/reference/generated/numpy.polyfit.html"><code>np.polyfit</code></a>
verwenden, um die Koeffizienten <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0528em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0528em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0528em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> eines Polynoms <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span>-ten Grades
<span class="katex-display"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.3179em;vertical-align:-0.4089em;"></span><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9089em;"><span style="top:-2.9511em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9579em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.0833em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0528em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0528em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0528em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0528em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7144em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4089em;"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9089em;"><span style="top:-2.9089em;"><span class="pstrut" style="height:2.9579em;"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4089em;"><span></span></span></span></span></span></span></span></span>
zu bestimmen, welches am besten zu den Daten passt. Diese Funktion
nimmt als Argumente die Arrays der unabhängigen Variable <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span> und
der abhängigen Variable <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span>, sowie den Grad des Polynoms <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span> entgegen und
gibt die Koeffizienten <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0528em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> zurück.</p>
<p><strong>(a) Polynomiale Regression mit <code>np.polyfit</code></strong></p>
<p>Wenden Sie die Funktion <code>np.polyfit</code> auf die Methylenblau-Daten an, um
ein Polynom 20. Grades zu fitten und plotten Sie das Polynom zusammen mit den Datenpunkten.</p>
<div id="admonition-tipp-1" class="admonition admonish-tip">
<div class="admonition-title">
<p>Tipp</p>
<p><a class="admonition-anchor-link" href="#admonition-tipp-1"></a></p>
</div>
<div>
<p>Zum Plotten der Polynomfunktion können Sie die Funktion
<a href="https://numpy.org/doc/stable/reference/generated/numpy.polyval.html"><code>np.polyval</code></a> verwenden, welche
die Funktionswerte des Polynoms für gegebene Werte von <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0528em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> und <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span> (d.h. <code>concentrations</code>) in
Form eines Arrays berechnet.</p>
</div>
</div>
<!-- 
Lösung:
```python
{{include ../codes/01-regression/exercise_01.py:exercise_02_a}}
```
-->
<p><strong>(b) Vorhersage von neuen Datenpunkten</strong></p>
<p>Aus dem Plot der polynomialen Regression (und ggf. den Residuen) können Sie erkennen,
dass das Polynom 20. Grades die Datenpunkte sehr gut anpasst. Dies ist auch nicht weiter
verwunderlich, da wir eine Funktion mit mind. 20 Parametern so anpassen können, dass sie
unsere 20 Datenpunkte perfekt wiedergibt. Allerdings haben wir in unserem
Code bisher lediglich die Datenpunkte, welche wir zum Fitten des Modells verwendet haben, zur
Visualisierung der Ergebnisse beachtet. Die Funktionswerte zwischen den Datenpunkten wurden
lediglich interpoliert. In der Regel möchten wir allerdings mit Hilfe unseres Modells auch
Vorhersagen für neue Datenpunkte erhalten.</p>
<p>Plotten Sie das gesamte Polynom 20. Grades zusammen mit den Datenpunkten in dem Interall
<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7804em;vertical-align:-0.136em;"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7719em;vertical-align:-0.136em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">50.0</span></span></span></span>. Definieren Sie sich dazu ein Array mit 1000 Werten mit Hilfe
der Funktion <a href="https://numpy.org/doc/stable/reference/generated/numpy.linspace.html"><code>np.linspace</code></a>
und berechnen Sie die Funktionswerte. Beschränken Sie die Darstellung des Plots auf den Bereich <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7804em;vertical-align:-0.136em;"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8304em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">2.0</span></span></span></span>.
Was beobachten Sie?</p>
<!-- 
Lösung:
```python
{{include ../codes/01-regression/exercise_01.py:exercise_02_b}}
```
-->

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../01-regression/02-linear_regression.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../01-regression/04-nonlinear_regression.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../01-regression/02-linear_regression.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../01-regression/04-nonlinear_regression.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->
        <script src=".././theme/pagetoc.js"></script>


    </div>
    </body>
</html>
